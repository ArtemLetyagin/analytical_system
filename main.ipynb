{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98687582",
   "metadata": {},
   "source": [
    "# Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea6ad5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from parse_pdf_terms_and_clauses import parse_terms_and_clauses_global, write_jsonl\n",
    "from parse_docx_terms import parse_docx_terms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4ceac7",
   "metadata": {},
   "source": [
    "### Extract - approved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25a561a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROCESSED: gost-r-iso-iec-20546-2021.pdf\n",
      "> Found 38 terms\n",
      "> Found 24 clauses\n",
      "PROCESSED: 83677.pdf\n",
      "> Found 18 terms\n",
      "> Found 31 clauses\n"
     ]
    }
   ],
   "source": [
    "approved_path = \"data/docs/approved\"\n",
    "out_terms = \"data/extract/approved\"\n",
    "\n",
    "for doc in os.listdir(approved_path):\n",
    "\n",
    "    pdf_file_path = f\"data/docs/approved/{doc}\"\n",
    "    standard_id = ''\n",
    "\n",
    "    terms, clauses = parse_terms_and_clauses_global(pdf_file_path, standard_id)\n",
    "\n",
    "    write_jsonl(f\"{out_terms}/terms_{doc}.jsonl\", terms)\n",
    "    write_jsonl(f\"{out_terms}/clauses_{doc}.jsonl\", clauses)\n",
    "\n",
    "    print(f\"PROCESSED: {doc}\")\n",
    "    print(f\"> Found {len(terms)} terms\")\n",
    "    print(f\"> Found {len(clauses)} clauses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09043e8",
   "metadata": {},
   "source": [
    "### Extract - draft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa239abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted: 60 terms\n",
      "Saved to: data/extract/draft/terms_Проект_ГОСТ_СППР_на_НК_б.docx.jsonl\n",
      "Extracted: 72 terms\n",
      "Saved to: data/extract/draft/terms_Проект_ГОСТ_КИТ_на_НК_б.docx.jsonl\n"
     ]
    }
   ],
   "source": [
    "draft_path = \"data/docs/draft\"\n",
    "out_path = \"data/extract/draft\"\n",
    "\n",
    "for doc in os.listdir(draft_path):\n",
    "\n",
    "    input_docx = f\"{draft_path}/{doc}\"\n",
    "    output_jsonl = f\"{out_path}/terms_{doc}.jsonl\"\n",
    "\n",
    "    parse_docx_terms(\n",
    "        input_docx=input_docx,\n",
    "        output_jsonl=output_jsonl\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd78bb89",
   "metadata": {},
   "source": [
    "# Load to VectorDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39b47977",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from OllamaEmbedder import OllamaEmbedder, ollama_embed\n",
    "from vector_db_utils import upsert_terms, build_retrieval_text, truncate_collection, delete_collections\n",
    "from parse_pdf_terms_and_clauses import load_jsonl\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bc16f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_DIR = \"chromadb_volume\"\n",
    "EMBED_MODEL = \"nomic-embed-text\"\n",
    "OLLAMA_URL = \"http://localhost:11434\"\n",
    "\n",
    "client = chromadb.PersistentClient(path=DB_DIR)\n",
    "embedder = OllamaEmbedder(model=EMBED_MODEL, base_url=OLLAMA_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba885dca",
   "metadata": {},
   "source": [
    "### approved - terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb8c1c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Коллекция 'terms_approved' удалена\n"
     ]
    }
   ],
   "source": [
    "# level -> choices=[\"national\", \"international\"]\n",
    "\n",
    "extra_md = {\"status\": \"approved\", \"level\": \"national\"}\n",
    "\n",
    "terms_paths = [\n",
    "    f\"data/extract/approved/{name}\" for name in os.listdir(\"data/extract/approved\")\n",
    "    if name.startswith(\"terms_\")\n",
    "]\n",
    "\n",
    "truncate_collection(\n",
    "    client=client,\n",
    "    collection_name=\"terms_approved\"\n",
    ")\n",
    "\n",
    "delete_collections(client=client, collection_name=\"terms_approved\")\n",
    "\n",
    "for terms_path in terms_paths:\n",
    "    rows = load_jsonl(terms_path)\n",
    "\n",
    "    upsert_terms(\n",
    "        client=client,\n",
    "        collection_name=\"terms_approved\",\n",
    "        rows=rows,\n",
    "        embedder=embedder,\n",
    "        text_builder=build_retrieval_text,\n",
    "        extra_md=extra_md,\n",
    "        batch_size=32,  # embeddings via HTTP, keep moderate\n",
    "    )   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee93afd9",
   "metadata": {},
   "source": [
    "### approved - clauses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aed2601a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Коллекция 'clauses_approved' удалена\n"
     ]
    }
   ],
   "source": [
    "# 2) Definitions collection: def only\n",
    "def_only = lambda r: (r.get(\"text\") or \"\").strip()\n",
    "\n",
    "extra_md = {\"status\": \"approved\", \"level\": \"national\"}\n",
    "\n",
    "defs_paths = [\n",
    "    f\"data/extract/approved/{name}\" for name in os.listdir(\"data/extract/approved\")\n",
    "    if name.startswith(\"clauses_\")\n",
    "]\n",
    "\n",
    "truncate_collection(\n",
    "    client=client,\n",
    "    collection_name=\"clauses_approved\"\n",
    ")\n",
    "\n",
    "delete_collections(client=client, collection_name=\"clauses_approved\")\n",
    "\n",
    "for defs_path in defs_paths:\n",
    "    rows = load_jsonl(defs_path)\n",
    "    upsert_terms(\n",
    "        client=client,\n",
    "        collection_name=\"clauses_approved\",\n",
    "        rows=rows,\n",
    "        embedder=embedder,\n",
    "        text_builder=def_only,\n",
    "        extra_md=extra_md,\n",
    "       batch_size=32,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46805d7f",
   "metadata": {},
   "source": [
    "### draft - terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74c82668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Коллекция 'terms_draft' удалена\n",
      "72\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "# level -> choices=[\"national\", \"international\"]\n",
    "\n",
    "extra_md = {\"status\": \"draft\", \"level\": \"national\"}\n",
    "\n",
    "terms_paths = [\n",
    "    f\"data/extract/draft/{name}\" for name in os.listdir(\"data/extract/draft\")\n",
    "    if name.startswith(\"terms_\")\n",
    "]\n",
    "\n",
    "truncate_collection(\n",
    "    client=client,\n",
    "    collection_name=\"terms_draft\"\n",
    ")\n",
    "\n",
    "delete_collections(client=client, collection_name=\"terms_draft\")\n",
    "\n",
    "for terms_path in terms_paths:\n",
    "    rows = load_jsonl(terms_path)\n",
    "    print(len(rows))\n",
    "    upsert_terms(\n",
    "        client=client,\n",
    "        collection_name=\"terms_draft\",\n",
    "        rows=rows,\n",
    "        embedder=embedder,\n",
    "        text_builder=build_retrieval_text,\n",
    "        extra_md=extra_md,\n",
    "        batch_size=32,  # embeddings via HTTP, keep moderate\n",
    "    )   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aaee136",
   "metadata": {},
   "source": [
    "# Docs score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1703e035",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vector_db_utils import retrieve\n",
    "import chromadb\n",
    "from OllamaEmbedder import OllamaEmbedder, ollama_embed\n",
    "from vector_db_utils import upsert_terms, build_retrieval_text, truncate_collection\n",
    "from parse_pdf_terms_and_clauses import load_jsonl\n",
    "import os\n",
    "import numpy as np\n",
    "from termsim import TermSim\n",
    "from defsim import DefSim\n",
    "\n",
    "DB_DIR = \"chromadb_volume\"\n",
    "EMBED_MODEL = \"nomic-embed-text\"\n",
    "OLLAMA_URL = \"http://localhost:11434\"\n",
    "\n",
    "client = chromadb.PersistentClient(path=DB_DIR)\n",
    "embedder = OllamaEmbedder(model=EMBED_MODEL, base_url=OLLAMA_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4587d771",
   "metadata": {},
   "outputs": [],
   "source": [
    "DRAFT_DOC_NAME = \"Проект_ГОСТ_КИТ_на_НК_б\"\n",
    "#DRAFT_DOC_NAME = \"Проект_ГОСТ_СППР_на_НК_б\"\n",
    "APPROVED_DOC_NAME = \"83677\"#\"gost-r-iso-iec-20546-2021\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f839c63e",
   "metadata": {},
   "source": [
    "### TermSim - example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33834868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04861111111111111\n"
     ]
    }
   ],
   "source": [
    "draft_rows = load_jsonl(f\"data/extract/draft/terms_{DRAFT_DOC_NAME}.docx.jsonl\")\n",
    "draft_terms = [r[\"term_ru\"] for r in draft_rows]\n",
    "\n",
    "approved_rows = load_jsonl(f\"data/extract/approved/terms_{APPROVED_DOC_NAME}.pdf.jsonl\")\n",
    "approved_terms = [r[\"term_ru\"] for r in approved_rows]\n",
    "\n",
    "term_score, result = TermSim(\n",
    "    draft_terms,\n",
    "    approved_terms\n",
    ")\n",
    "\n",
    "print(term_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c874d23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'term_a': 'информация', 'best_term_b': 'информация', 'term_score': 1.0},\n",
       " {'term_a': 'обработка информации (данных)',\n",
       "  'best_term_b': 'безопасность информации [данных]',\n",
       "  'term_score': 0.5},\n",
       " {'term_a': 'искусственный интеллект; ИИ (artificial intelligence, AI)',\n",
       "  'best_term_b': 'система искусственного интеллекта',\n",
       "  'term_score': 0.5},\n",
       " {'term_a': 'знания (в искусственном интеллекте)',\n",
       "  'best_term_b': 'система искусственного интеллекта',\n",
       "  'term_score': 0.5},\n",
       " {'term_a': 'сильный искусственный интеллект',\n",
       "  'best_term_b': 'система искусственного интеллекта',\n",
       "  'term_score': 0.5},\n",
       " {'term_a': 'общий искусственный интеллект',\n",
       "  'best_term_b': 'система искусственного интеллекта',\n",
       "  'term_score': 0.5}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# termsim - pairs\n",
    "[r for r in result if r[\"best_term_b\"] is not None]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cce8534",
   "metadata": {},
   "source": [
    "### DefSim - example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57d2bb77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8768839831736185\n"
     ]
    }
   ],
   "source": [
    "draft_rows = load_jsonl(f\"data/extract/draft/terms_{DRAFT_DOC_NAME}.docx.jsonl\")\n",
    "draft_defintions = [r[\"definition\"].split(\"П р и м е ч а н и е\")[0] for r in draft_rows]\n",
    "\n",
    "approved_rows = load_jsonl(f\"data/extract/approved/terms_{APPROVED_DOC_NAME}.pdf.jsonl\")\n",
    "approved_defintions = [r[\"definition\"].split(\"П р и м е ч а н и е\")[0] for r in approved_rows]\n",
    "\n",
    "def_score, stats = DefSim(\n",
    "    draft_defintions,\n",
    "    approved_defintions,\n",
    "    ollama_embed=ollama_embed\n",
    ")\n",
    "\n",
    "print(def_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6533d2e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a_idx': 53,\n",
       " 'b_idx': 14,\n",
       " 'a_text': 'Набор средств обработки данных, используемый для организации сбора, хранения, обработки, передачи и использования данных в составе когнитивной информационной системы.',\n",
       " 'b_text': 'Устройство хранения данных, которое обеспечивает постоянный доступ к данным для эффективной совместной работы участников процесса дистанционного мониторинга по сети.',\n",
       " 'sim': 0.9271739721298218}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats['closest_pairs'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af93fbe8",
   "metadata": {},
   "source": [
    "### ClauseSim - example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d9c8c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.889443963321376\n"
     ]
    }
   ],
   "source": [
    "draft_rows = load_jsonl(f\"data/extract/draft/terms_{DRAFT_DOC_NAME}.docx.jsonl\")\n",
    "draft_defintions = [r[\"definition\"].split(\"П р и м е ч а н и е\")[0] for r in draft_rows]\n",
    "\n",
    "approved_rows = load_jsonl(f\"data/extract/approved/clauses_{APPROVED_DOC_NAME}.pdf.jsonl\")\n",
    "approved_defintions = [r[\"text\"].split(\"П р и м е ч а н и е\")[0] for r in approved_rows]\n",
    "\n",
    "clau_score, stats = DefSim(\n",
    "    draft_defintions,\n",
    "    approved_defintions,\n",
    "    ollama_embed=ollama_embed\n",
    ")\n",
    "\n",
    "print(clau_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c22822d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a_idx': 57,\n",
       " 'b_idx': 25,\n",
       " 'a_text': 'Интерфейс когнитивной информационной системы, одновременно использующий несколько средств обработки разнородной информации, передаваемой пользователем когнитивной информационной системы по различным каналам коммуникации (речевой, текстовый, аудиальный, визуальный, тактильный и так далее).',\n",
       " 'b_text': 'Рекомендуется использование в процессе работы стандартизированной терминологии (согласно НСИ системы здравоохранения), а также стандартизированных форматов файлов для более точного сбора информации, с возможностью обмена между организациями, осуществляющими СДМ на основе ИИ, унифицированными данными для лечебно-профилактических, научных и иных целей.',\n",
       " 'sim': 0.9306917190551758}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats[\"closest_pairs\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "314e7988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6049796858687019\n"
     ]
    }
   ],
   "source": [
    "total_score = (term_score + def_score + clau_score) / 3\n",
    "\n",
    "print(total_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586ca8e2",
   "metadata": {},
   "source": [
    "# Retrieve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5379da2c",
   "metadata": {},
   "source": [
    "### Approved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d99e34b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms_approved_collection = client.get_or_create_collection(\"terms_approved\")\n",
    "draft_collection = client.get_or_create_collection(\"terms_draft\")\n",
    "clauses_approved_collection = client.get_or_create_collection(\"clauses_approved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82a2e4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms_approved = {}\n",
    "\n",
    "for row in terms_approved_collection.get()[\"metadatas\"]:\n",
    "    source_file = row[\"source_file\"]\n",
    "\n",
    "    if source_file not in terms_approved:\n",
    "        terms_approved[source_file] = set()\n",
    "    \n",
    "    terms_approved[source_file].add(row[\"term_ru\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c058ac3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['пациент',\n",
       " 'врачебная комиссия',\n",
       " 'программный продукт',\n",
       " 'сетевое хранилище (сетевая система хранения данных)',\n",
       " 'информация']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(terms_approved[\"83677.pdf\"])[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddd154f",
   "metadata": {},
   "source": [
    "### Retrive draft by doc name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8be69a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "draft_doc_name = \"Проект_ГОСТ_КИТ_на_НК_б.docx\"\n",
    "\n",
    "draft_docs = draft_collection.get(\n",
    "    where={\"source_file\": draft_doc_name}\n",
    ")[\"metadatas\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c713571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'level': 'national',\n",
       " 'term_ru_norm': 'информация',\n",
       " 'doc_type': 'term',\n",
       " 'source_file': 'Проект_ГОСТ_КИТ_на_НК_б.docx',\n",
       " 'status': 'draft',\n",
       " 'term_ru': 'информация',\n",
       " 'term_en': 'information',\n",
       " 'def_len': 141,\n",
       " 'section_path': ''}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draft_docs[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a113936",
   "metadata": {},
   "source": [
    "### Retrive by word - example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "93644edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_text = \"авторизация\"\n",
    "q_emb = ollama_embed([query_text], model=\"nomic-embed-text\")[0]\n",
    "\n",
    "res = terms_approved_collection.query(\n",
    "    query_embeddings=[q_emb],\n",
    "    n_results=10,\n",
    "    where={\"doc_type\": \"term\"},  # опционально\n",
    "    include=[\"documents\", \"metadatas\", \"distances\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "01ddec9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TERM_RU: авторизация\\nDEF: Проверка, подтверждение и предоставление прав логического доступа при осуществлении субъектами доступа логического доступа. [ГОСТ Р 57580.1—2017, пункт 3.15]',\n",
       " 'TERM_RU: система дистанционного мониторинга\\nDEF: Интеллектуальная информационная система, предназначенная для сбора, хранения, обработки и представления информации, касающейся деятельности медицинских организаций и предоставляемых ими услуг в отношении дистанционного наблюдения за состоянием здоровья пациента.',\n",
       " 'TERM_RU: информация\\nDEF: Сведения (сообщения, данные) независимо от формы их представления. [[1], статья 2]']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"documents\"][0][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51840fed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
